{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "basedir = '../'\n",
    "sys.path.append(basedir)\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from synth_data import HldaDataGenerator\n",
    "from hlda import NCRPNode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthetic data test for hierarchical LDA inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['w0' 'w1' 'w2' 'w3' 'w4']\n",
      " ['w5' 'w6' 'w7' 'w8' 'w9']\n",
      " ['w10' 'w11' 'w12' 'w13' 'w14']\n",
      " ['w15' 'w16' 'w17' 'w18' 'w19']\n",
      " ['w20' 'w21' 'w22' 'w23' 'w24']\n",
      " ['w25' 'w26' 'w27' 'w28' 'w29']\n",
      " ['w30' 'w31' 'w32' 'w33' 'w34']\n",
      " ['w35' 'w36' 'w37' 'w38' 'w39']\n",
      " ['w40' 'w41' 'w42' 'w43' 'w44']\n",
      " ['w45' 'w46' 'w47' 'w48' 'w49']\n",
      " ['w50' 'w51' 'w52' 'w53' 'w54']\n",
      " ['w55' 'w56' 'w57' 'w58' 'w59']\n",
      " ['w60' 'w61' 'w62' 'w63' 'w64']\n",
      " ['w65' 'w66' 'w67' 'w68' 'w69']\n",
      " ['w70' 'w71' 'w72' 'w73' 'w74']\n",
      " ['w75' 'w76' 'w77' 'w78' 'w79']\n",
      " ['w80' 'w81' 'w82' 'w83' 'w84']\n",
      " ['w85' 'w86' 'w87' 'w88' 'w89']\n",
      " ['w90' 'w91' 'w92' 'w93' 'w94']\n",
      " ['w95' 'w96' 'w97' 'w98' 'w99']]\n"
     ]
    }
   ],
   "source": [
    "n_rows = 20\n",
    "n_cols = 5\n",
    "vocab_mat = np.zeros((n_rows, n_cols), dtype=np.object)\n",
    "word_count = 0\n",
    "for i in range(n_rows):\n",
    "    for j in range(n_cols):\n",
    "        vocab_mat[i, j] = 'w%s' % word_count\n",
    "        word_count += 1\n",
    "        \n",
    "print vocab_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w0', 'w1', 'w2', 'w3', 'w4', 'w5', 'w6', 'w7', 'w8', 'w9', 'w10', 'w11', 'w12', 'w13', 'w14', 'w15', 'w16', 'w17', 'w18', 'w19', 'w20', 'w21', 'w22', 'w23', 'w24', 'w25', 'w26', 'w27', 'w28', 'w29', 'w30', 'w31', 'w32', 'w33', 'w34', 'w35', 'w36', 'w37', 'w38', 'w39', 'w40', 'w41', 'w42', 'w43', 'w44', 'w45', 'w46', 'w47', 'w48', 'w49', 'w50', 'w51', 'w52', 'w53', 'w54', 'w55', 'w56', 'w57', 'w58', 'w59', 'w60', 'w61', 'w62', 'w63', 'w64', 'w65', 'w66', 'w67', 'w68', 'w69', 'w70', 'w71', 'w72', 'w73', 'w74', 'w75', 'w76', 'w77', 'w78', 'w79', 'w80', 'w81', 'w82', 'w83', 'w84', 'w85', 'w86', 'w87', 'w88', 'w89', 'w90', 'w91', 'w92', 'w93', 'w94', 'w95', 'w96', 'w97', 'w98', 'w99']\n"
     ]
    }
   ],
   "source": [
    "vocab = vocab_mat.flatten().tolist()\n",
    "print vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Assign Documents to Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "node 0 (level=0, documents=100): \n",
      "    node 1 (level=1, documents=78): \n",
      "        node 2 (level=2, documents=11): \n",
      "        node 3 (level=2, documents=49): \n",
      "        node 4 (level=2, documents=17): \n",
      "        node 14 (level=2, documents=1): \n",
      "    node 5 (level=1, documents=16): \n",
      "        node 6 (level=2, documents=15): \n",
      "        node 7 (level=2, documents=1): \n",
      "    node 8 (level=1, documents=4): \n",
      "        node 9 (level=2, documents=1): \n",
      "        node 13 (level=2, documents=3): \n",
      "    node 10 (level=1, documents=2): \n",
      "        node 11 (level=2, documents=1): \n",
      "        node 12 (level=2, documents=1): \n"
     ]
    }
   ],
   "source": [
    "NCRPNode.total_nodes = 0\n",
    "NCRPNode.last_node_id = 0\n",
    "num_levels = 3\n",
    "gamma = 1\n",
    "num_docs = 100\n",
    "\n",
    "root_node = NCRPNode(num_levels, vocab)\n",
    "document_path = {}\n",
    "unique_nodes = set()\n",
    "unique_nodes.add(root_node)\n",
    "for d in range(num_docs):\n",
    "\n",
    "    # populate nodes into the path of this document\n",
    "    path = np.zeros(num_levels, dtype=np.object)\n",
    "    path[0] = root_node\n",
    "    root_node.customers += 1 # always add to the root node first\n",
    "    for level in range(1, num_levels):\n",
    "        # at each level, a node is selected by its parent node based on the CRP prior\n",
    "        parent_node = path[level-1]\n",
    "        level_node = parent_node.select(gamma)\n",
    "        level_node.customers += 1\n",
    "        path[level] = level_node\n",
    "        unique_nodes.add(level_node)\n",
    "\n",
    "    # set the leaf node for this document                 \n",
    "    document_path[d] = path\n",
    "    \n",
    "unique_nodes = sorted(unique_nodes, key=lambda x: x.node_id)\n",
    "print len(unique_nodes)\n",
    "    \n",
    "def print_node(node, indent, node_topic):\n",
    "    out = '    ' * indent\n",
    "    out += 'node %d (level=%d, documents=%d): ' % (node.node_id, node.level, node.customers)\n",
    "    if node in node_topic:\n",
    "        probs, words = node_topic[node]\n",
    "        out += ' '.join(words)\n",
    "    print out        \n",
    "    for child in node.children:\n",
    "        print_node(child, indent+1, node_topic)        \n",
    "\n",
    "node_topic = {}\n",
    "print_node(root_node, 0, node_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Assign Each Node Along the Tree to a Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.12433608  0.02100025  0.00667487  0.09811402  0.01536349  0.08651545\n",
      "  0.05741028  0.01577271  0.10447763  0.03088607  0.01995532  0.0239845\n",
      "  0.07063322  0.05648605  0.12936004  0.03776339  0.01920202  0.02296246\n",
      "  0.00722688  0.05187527]\n",
      "['w0' 'w5' 'w10' 'w15' 'w20' 'w25' 'w30' 'w35' 'w40' 'w45' 'w50' 'w55'\n",
      " 'w60' 'w65' 'w70' 'w75' 'w80' 'w85' 'w90' 'w95']\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def get_words(vocab_mat, eta, pos, dim):\n",
    "\n",
    "    if dim == 'row':\n",
    "        words = vocab_mat[pos]\n",
    "    elif dim == 'col':\n",
    "        words = vocab_mat[:, pos]\n",
    "    \n",
    "    k = len(words)\n",
    "    eta = [eta] * k\n",
    "    probs = np.random.dirichlet(eta)\n",
    "    return probs, words\n",
    "    \n",
    "pos = 0\n",
    "eta = 1\n",
    "probs, words = get_words(vocab_mat, eta, pos, 'col')\n",
    "print probs\n",
    "print words\n",
    "print np.sum(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "node_topic = {}\n",
    "node_topic[unique_nodes[0]] = get_words(vocab_mat, eta, 0, 'row') \n",
    "node_topic[unique_nodes[1]] = get_words(vocab_mat, eta, 1, 'row') \n",
    "node_topic[unique_nodes[2]] = get_words(vocab_mat, eta, 2, 'row') \n",
    "node_topic[unique_nodes[3]] = get_words(vocab_mat, eta, 3, 'row') \n",
    "node_topic[unique_nodes[4]] = get_words(vocab_mat, eta, 4, 'row') \n",
    "node_topic[unique_nodes[5]] = get_words(vocab_mat, eta, 5, 'row') \n",
    "node_topic[unique_nodes[6]] = get_words(vocab_mat, eta, 6, 'row') \n",
    "node_topic[unique_nodes[7]] = get_words(vocab_mat, eta, 7, 'row') \n",
    "node_topic[unique_nodes[8]] = get_words(vocab_mat, eta, 8, 'row') \n",
    "node_topic[unique_nodes[9]] = get_words(vocab_mat, eta, 9, 'row') \n",
    "node_topic[unique_nodes[10]] = get_words(vocab_mat, eta, 10, 'row') \n",
    "node_topic[unique_nodes[11]] = get_words(vocab_mat, eta, 11, 'row') \n",
    "node_topic[unique_nodes[12]] = get_words(vocab_mat, eta, 12, 'row') \n",
    "node_topic[unique_nodes[13]] = get_words(vocab_mat, eta, 13, 'row') \n",
    "node_topic[unique_nodes[14]] = get_words(vocab_mat, eta, 14, 'row') \n",
    "print len(node_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node 0 (level=0, documents=100): w0 w1 w2 w3 w4\n",
      "    node 1 (level=1, documents=78): w5 w6 w7 w8 w9\n",
      "        node 2 (level=2, documents=11): w10 w11 w12 w13 w14\n",
      "        node 3 (level=2, documents=49): w15 w16 w17 w18 w19\n",
      "        node 4 (level=2, documents=17): w20 w21 w22 w23 w24\n",
      "        node 14 (level=2, documents=1): w70 w71 w72 w73 w74\n",
      "    node 5 (level=1, documents=16): w25 w26 w27 w28 w29\n",
      "        node 6 (level=2, documents=15): w30 w31 w32 w33 w34\n",
      "        node 7 (level=2, documents=1): w35 w36 w37 w38 w39\n",
      "    node 8 (level=1, documents=4): w40 w41 w42 w43 w44\n",
      "        node 9 (level=2, documents=1): w45 w46 w47 w48 w49\n",
      "        node 13 (level=2, documents=3): w65 w66 w67 w68 w69\n",
      "    node 10 (level=1, documents=2): w50 w51 w52 w53 w54\n",
      "        node 11 (level=2, documents=1): w55 w56 w57 w58 w59\n",
      "        node 12 (level=2, documents=1): w60 w61 w62 w63 w64\n"
     ]
    }
   ],
   "source": [
    "print_node(root_node, 0, node_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Generate Words in a Document Based on Its Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_document(topics, theta, doc_len):\n",
    "\n",
    "    # for every word in the vocab for this document\n",
    "    doc = []\n",
    "    for n in range(doc_len):\n",
    "\n",
    "        # sample a new topic index    \n",
    "        k = np.random.multinomial(1, theta).argmax()\n",
    "\n",
    "        # sample a new word from the word distribution of topic k\n",
    "        probs, words = topics[k]\n",
    "        w = np.random.multinomial(1, probs).argmax()\n",
    "        doc_word = words[w]\n",
    "\n",
    "        doc.append(doc_word)\n",
    "\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "alpha = [2.0, 1.0, 0.5]\n",
    "alpha = [1.0, 1.0, 1.0]\n",
    "doc_len = 50\n",
    "for d in range(num_docs):\n",
    "    path = document_path[d]\n",
    "    topics = [node_topic[node] for node in path]\n",
    "    theta = np.random.mtrand.dirichlet(alpha)\n",
    "    doc = generate_document(topics, theta, doc_len)\n",
    "    corpus.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "outdir = '/Users/joewandy/Dropbox/Analysis/hLDA/data/synthetic/'\n",
    "for d in range(len(corpus)):\n",
    "    doc = corpus[d]\n",
    "    file_name = 'doc_%d.txt' % d\n",
    "    file_path = os.path.join(outdir, file_name)\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(\"%s\\n\" % ' '.join(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Run hLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 50\n"
     ]
    }
   ],
   "source": [
    "print len(vocab), len(corpus), len(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert corpus words into indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_corpus = []\n",
    "for doc in corpus:\n",
    "    new_doc = []\n",
    "    for word in doc:\n",
    "        word_idx = vocab.index(word)\n",
    "        new_doc.append(word_idx)\n",
    "    new_corpus.append(new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n",
      "['w14', 'w10', 'w6', 'w10', 'w14', 'w11', 'w10', 'w6', 'w6', 'w8', 'w0', 'w14', 'w11', 'w1', 'w0', 'w10', 'w14', 'w14', 'w5', 'w14', 'w10', 'w11', 'w0', 'w7', 'w1', 'w14', 'w10', 'w10', 'w14', 'w5', 'w4', 'w13', 'w10', 'w14', 'w5', 'w5', 'w13', 'w11', 'w1', 'w10', 'w8', 'w4', 'w4', 'w10', 'w10', 'w14', 'w7', 'w14', 'w10', 'w9']\n",
      "[14, 10, 6, 10, 14, 11, 10, 6, 6, 8, 0, 14, 11, 1, 0, 10, 14, 14, 5, 14, 10, 11, 0, 7, 1, 14, 10, 10, 14, 5, 4, 13, 10, 14, 5, 5, 13, 11, 1, 10, 8, 4, 4, 10, 10, 14, 7, 14, 10, 9]\n"
     ]
    }
   ],
   "source": [
    "print len(vocab), len(new_corpus)\n",
    "print corpus[0]\n",
    "print new_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hlda import HierarchicalLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0] 1 1\n"
     ]
    }
   ],
   "source": [
    "print alpha, gamma, eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HierarchicalLDA sampling\n",
      "..........\n",
      "topic 0 (level=0, total_words=1652, documents=100): w1, w4, w0, w5, w2, w3, w9, w6, w8, w7, \n",
      "    topic 1 (level=1, total_words=169, documents=25): w24, w5, w6, w9, w22, w20, w7, w8, w21, w3, \n",
      "        topic 2 (level=2, total_words=245, documents=12): w10, w14, w11, w13, w5, w12, w6, w8, w1, w3, \n",
      "        topic 3 (level=2, total_words=122, documents=8): w40, w44, w43, w49, w68, w69, w67, w66, w4, w1, \n",
      "        topic 14 (level=2, total_words=75, documents=2): w53, w52, w50, w54, w59, w58, w55, w60, w57, w51, \n",
      "        topic 34 (level=2, total_words=48, documents=2): w71, w74, w73, w8, w7, w72, w15, w9, w70, w5, \n",
      "        topic 35 (level=2, total_words=39, documents=1): w37, w39, w35, w38, w36, w26, w0, w28, w29, w2, \n",
      "    topic 6 (level=1, total_words=205, documents=26): w6, w5, w24, w17, w16, w18, w4, w9, w1, w22, \n",
      "        topic 7 (level=2, total_words=657, documents=26): w16, w17, w1, w4, w19, w18, w15, w2, w0, w5, \n",
      "    topic 8 (level=1, total_words=347, documents=49): w24, w5, w6, w17, w16, w20, w8, w22, w18, w19, \n",
      "        topic 9 (level=2, total_words=555, documents=18): w25, w31, w34, w30, w27, w26, w32, w33, w1, w29, \n",
      "        topic 13 (level=2, total_words=886, documents=31): w5, w6, w9, w8, w7, w16, w1, w17, w2, w4, \n",
      "..........\n",
      "topic 0 (level=0, total_words=1784, documents=100): w1, w4, w0, w2, w5, w3, w9, w7, w8, w16, \n",
      "    topic 1 (level=1, total_words=198, documents=22): w24, w5, w6, w20, w22, w9, w8, w1, w2, w21, \n",
      "        topic 2 (level=2, total_words=257, documents=12): w10, w14, w11, w5, w13, w6, w8, w9, w12, w0, \n",
      "        topic 3 (level=2, total_words=127, documents=5): w40, w4, w44, w43, w49, w69, w68, w67, w66, w65, \n",
      "        topic 14 (level=2, total_words=75, documents=3): w53, w52, w50, w54, w59, w58, w55, w60, w57, w51, \n",
      "        topic 46 (level=2, total_words=39, documents=1): w37, w39, w35, w38, w36, w26, w0, w28, w29, w3, \n",
      "        topic 52 (level=2, total_words=0, documents=1): w99, w36, w26, w27, w28, w29, w30, w31, w32, w33, \n",
      "    topic 6 (level=1, total_words=40, documents=28): w5, w6, w8, w17, w9, w3, w7, w16, w32, w31, \n",
      "        topic 7 (level=2, total_words=683, documents=27): w16, w17, w18, w19, w6, w15, w5, w4, w1, w7, \n",
      "        topic 53 (level=2, total_words=48, documents=1): w71, w74, w73, w6, w8, w72, w9, w70, w5, w40, \n",
      "    topic 8 (level=1, total_words=264, documents=50): w24, w5, w6, w20, w7, w22, w8, w9, w1, w2, \n",
      "        topic 9 (level=2, total_words=514, documents=15): w25, w31, w34, w30, w27, w26, w32, w33, w29, w28, \n",
      "        topic 13 (level=2, total_words=971, documents=35): w5, w6, w9, w8, w7, w16, w17, w18, w0, w19, \n",
      "..........\n",
      "topic 0 (level=0, total_words=1691, documents=100): w1, w4, w0, w2, w3, w9, w7, w8, w15, w18, \n",
      "    topic 1 (level=1, total_words=1, documents=16): w65, w99, w35, w26, w27, w28, w29, w30, w31, w32, \n",
      "        topic 2 (level=2, total_words=279, documents=10): w10, w14, w5, w11, w13, w6, w9, w8, w12, w7, \n",
      "        topic 3 (level=2, total_words=122, documents=4): w40, w44, w43, w4, w69, w68, w49, w66, w67, w65, \n",
      "        topic 14 (level=2, total_words=75, documents=2): w53, w52, w50, w54, w59, w58, w1, w60, w55, w57, \n",
      "    topic 6 (level=1, total_words=48, documents=28): w24, w22, w7, w21, w20, w9, w0, w6, w1, w19, \n",
      "        topic 7 (level=2, total_words=741, documents=26): w16, w17, w5, w6, w18, w19, w15, w4, w9, w7, \n",
      "        topic 71 (level=2, total_words=38, documents=1): w37, w39, w35, w36, w38, w26, w28, w29, w0, w40, \n",
      "        topic 72 (level=2, total_words=49, documents=1): w71, w74, w73, w8, w5, w6, w72, w9, w70, w40, \n",
      "    topic 8 (level=1, total_words=291, documents=56): w24, w20, w5, w22, w6, w9, w7, w8, w3, w21, \n",
      "        topic 9 (level=2, total_words=512, documents=15): w25, w31, w34, w30, w27, w26, w32, w33, w29, w28, \n",
      "        topic 13 (level=2, total_words=1153, documents=41): w5, w6, w9, w8, w7, w16, w17, w18, w15, w19, \n",
      "..........\n",
      "topic 0 (level=0, total_words=1670, documents=100): w1, w4, w0, w2, w3, w5, w7, w8, w17, w9, \n",
      "    topic 1 (level=1, total_words=52, documents=16): w24, w20, w5, w6, w22, w9, w1, w21, w8, w66, \n",
      "        topic 2 (level=2, total_words=288, documents=10): w10, w14, w5, w11, w13, w6, w0, w8, w9, w4, \n",
      "        topic 3 (level=2, total_words=131, documents=4): w40, w44, w43, w4, w1, w49, w68, w69, w67, w65, \n",
      "        topic 14 (level=2, total_words=75, documents=2): w53, w52, w50, w54, w59, w58, w3, w55, w60, w4, \n",
      "    topic 6 (level=1, total_words=54, documents=28): w24, w6, w22, w20, w9, w2, w7, w73, w8, w5, \n",
      "        topic 7 (level=2, total_words=702, documents=26): w16, w17, w5, w18, w6, w19, w15, w9, w4, w7, \n",
      "        topic 91 (level=2, total_words=49, documents=2): w71, w74, w73, w5, w8, w72, w6, w7, w9, w70, \n",
      "    topic 8 (level=1, total_words=275, documents=56): w24, w20, w5, w22, w6, w8, w9, w2, w21, w0, \n",
      "        topic 9 (level=2, total_words=507, documents=16): w25, w31, w34, w30, w27, w26, w32, w33, w29, w28, \n",
      "        topic 13 (level=2, total_words=1155, documents=39): w5, w6, w9, w8, w7, w16, w17, w1, w2, w18, \n",
      "        topic 92 (level=2, total_words=42, documents=1): w37, w39, w35, w36, w38, w26, w4, w28, w29, w0, \n",
      "..........\n",
      "topic 0 (level=0, total_words=1696, documents=100): w1, w4, w0, w2, w3, w9, w5, w8, w16, w7, \n",
      "    topic 1 (level=1, total_words=8, documents=16): w5, w2, w9, w40, w72, w14, w99, w35, w27, w28, \n",
      "        topic 2 (level=2, total_words=260, documents=9): w10, w14, w11, w5, w13, w6, w8, w12, w9, w7, \n",
      "        topic 3 (level=2, total_words=127, documents=4): w40, w4, w44, w43, w49, w69, w68, w67, w66, w65, \n",
      "        topic 14 (level=2, total_words=78, documents=2): w53, w52, w50, w54, w59, w58, w4, w55, w60, w57, \n",
      "        topic 114 (level=2, total_words=47, documents=1): w71, w74, w73, w6, w8, w5, w7, w70, w44, w32, \n",
      "    topic 6 (level=1, total_words=92, documents=29): w24, w22, w6, w20, w2, w21, w7, w8, w9, w1, \n",
      "        topic 7 (level=2, total_words=714, documents=26): w17, w16, w5, w6, w19, w18, w15, w9, w7, w8, \n",
      "        topic 111 (level=2, total_words=0, documents=1): w99, w36, w26, w27, w28, w29, w30, w31, w32, w33, \n",
      "        topic 112 (level=2, total_words=38, documents=1): w37, w39, w35, w36, w38, w26, w28, w29, w0, w40, \n",
      "        topic 113 (level=2, total_words=0, documents=1): w99, w36, w26, w27, w28, w29, w30, w31, w32, w33, \n",
      "    topic 8 (level=1, total_words=226, documents=55): w24, w20, w22, w6, w7, w1, w5, w21, w9, w0, \n",
      "        topic 9 (level=2, total_words=519, documents=15): w25, w31, w34, w30, w27, w26, w32, w33, w29, w28, \n",
      "        topic 13 (level=2, total_words=1195, documents=40): w5, w6, w9, w8, w7, w16, w17, w1, w18, w0, \n",
      "..........\n",
      "topic 0 (level=0, total_words=1727, documents=100): w1, w4, w0, w2, w3, w5, w9, w7, w8, w6, \n",
      "    topic 1 (level=1, total_words=25, documents=17): w24, w20, w6, w8, w9, w21, w48, w4, w5, w38, \n",
      "        topic 2 (level=2, total_words=265, documents=10): w10, w14, w11, w5, w13, w6, w9, w8, w12, w4, \n",
      "        topic 3 (level=2, total_words=116, documents=4): w40, w44, w43, w49, w69, w68, w67, w66, w65, w4, \n",
      "        topic 14 (level=2, total_words=81, documents=2): w53, w52, w50, w54, w59, w58, w4, w0, w55, w60, \n",
      "        topic 135 (level=2, total_words=50, documents=1): w71, w74, w73, w8, w5, w6, w72, w9, w70, w7, \n",
      "    topic 6 (level=1, total_words=52, documents=28): w24, w22, w6, w2, w20, w5, w7, w21, w9, w1, \n",
      "        topic 7 (level=2, total_words=709, documents=27): w16, w17, w5, w18, w6, w19, w15, w4, w7, w8, \n",
      "        topic 134 (level=2, total_words=0, documents=1): w99, w36, w26, w27, w28, w29, w30, w31, w32, w33, \n",
      "    topic 8 (level=1, total_words=269, documents=55): w24, w20, w6, w22, w8, w1, w5, w0, w9, w21, \n",
      "        topic 9 (level=2, total_words=500, documents=16): w25, w31, w34, w30, w27, w26, w32, w33, w29, w28, \n",
      "        topic 13 (level=2, total_words=1164, documents=38): w5, w6, w9, w8, w7, w16, w17, w1, w4, w18, \n",
      "        topic 133 (level=2, total_words=42, documents=1): w37, w39, w35, w38, w36, w0, w26, w2, w28, w29, \n",
      "..........\n",
      "topic 0 (level=0, total_words=1728, documents=100): w1, w4, w0, w2, w3, w5, w9, w7, w8, w15, \n",
      "    topic 1 (level=1, total_words=44, documents=17): w24, w20, w5, w6, w22, w8, w9, w21, w12, w33, \n",
      "        topic 2 (level=2, total_words=275, documents=10): w10, w14, w11, w5, w6, w13, w8, w4, w9, w12, \n",
      "        topic 3 (level=2, total_words=130, documents=4): w40, w4, w44, w43, w49, w69, w68, w67, w65, w66, \n",
      "        topic 14 (level=2, total_words=75, documents=2): w53, w52, w50, w54, w59, w58, w55, w60, w57, w51, \n",
      "        topic 153 (level=2, total_words=38, documents=1): w37, w39, w35, w38, w36, w26, w28, w29, w3, w44, \n",
      "    topic 6 (level=1, total_words=52, documents=27): w24, w22, w4, w6, w9, w20, w21, w15, w8, w7, \n",
      "        topic 7 (level=2, total_words=726, documents=27): w16, w17, w5, w18, w6, w19, w15, w4, w1, w8, \n",
      "    topic 8 (level=1, total_words=236, documents=56): w24, w20, w22, w6, w9, w8, w1, w21, w7, w4, \n",
      "        topic 9 (level=2, total_words=503, documents=15): w25, w31, w34, w30, w27, w26, w32, w33, w29, w28, \n",
      "        topic 13 (level=2, total_words=1143, documents=39): w5, w6, w9, w8, w7, w16, w17, w0, w18, w15, \n",
      "        topic 154 (level=2, total_words=0, documents=1): w99, w36, w26, w27, w28, w29, w30, w31, w32, w33, \n",
      "        topic 155 (level=2, total_words=50, documents=1): w71, w74, w73, w8, w5, w6, w72, w9, w70, w7, \n",
      "..........\n",
      "topic 0 (level=0, total_words=1720, documents=100): w1, w4, w0, w2, w3, w5, w7, w8, w9, w6, \n",
      "    topic 1 (level=1, total_words=101, documents=19): w24, w22, w6, w20, w1, w4, w21, w2, w7, w9, \n",
      "        topic 2 (level=2, total_words=271, documents=10): w10, w14, w11, w5, w13, w9, w6, w8, w12, w3, \n",
      "        topic 3 (level=2, total_words=121, documents=5): w40, w44, w43, w49, w68, w69, w4, w67, w66, w65, \n",
      "        topic 14 (level=2, total_words=73, documents=2): w53, w52, w50, w54, w59, w58, w55, w60, w57, w51, \n",
      "        topic 173 (level=2, total_words=38, documents=1): w37, w39, w38, w35, w36, w0, w26, w28, w29, w3, \n",
      "        topic 174 (level=2, total_words=50, documents=1): w71, w74, w73, w8, w5, w6, w72, w9, w70, w7, \n",
      "    topic 6 (level=1, total_words=3, documents=25): w4, w17, w15, w99, w36, w28, w29, w30, w31, w32, \n",
      "        topic 7 (level=2, total_words=709, documents=25): w16, w17, w5, w6, w18, w19, w15, w9, w8, w7, \n",
      "    topic 8 (level=1, total_words=247, documents=56): w24, w20, w6, w22, w5, w8, w9, w7, w3, w21, \n",
      "        topic 9 (level=2, total_words=499, documents=16): w25, w31, w34, w30, w27, w26, w32, w33, w29, w28, \n",
      "        topic 13 (level=2, total_words=1168, documents=40): w5, w6, w9, w8, w7, w16, w17, w4, w2, w18, \n",
      "..........\n",
      "topic 0 (level=0, total_words=1689, documents=100): w1, w4, w0, w2, w3, w16, w7, w5, w9, w15, \n",
      "    topic 1 (level=1, total_words=9, documents=15): w5, w14, w1, w3, w8, w9, w99, w33, w36, w35, \n",
      "        topic 2 (level=2, total_words=272, documents=9): w10, w14, w11, w5, w6, w13, w9, w8, w12, w7, \n",
      "        topic 3 (level=2, total_words=119, documents=4): w40, w44, w43, w49, w69, w68, w67, w66, w65, w0, \n",
      "        topic 14 (level=2, total_words=76, documents=2): w53, w52, w50, w54, w59, w58, w55, w0, w60, w57, \n",
      "    topic 6 (level=1, total_words=7, documents=26): w17, w28, w1, w7, w16, w15, w36, w29, w30, w31, \n",
      "        topic 7 (level=2, total_words=723, documents=25): w16, w17, w5, w6, w18, w19, w15, w9, w8, w1, \n",
      "        topic 195 (level=2, total_words=37, documents=1): w37, w39, w35, w36, w38, w26, w29, w0, w41, w32, \n",
      "    topic 8 (level=1, total_words=286, documents=57): w24, w20, w22, w1, w5, w6, w8, w2, w21, w4, \n",
      "        topic 9 (level=2, total_words=501, documents=15): w25, w31, w34, w30, w27, w26, w32, w33, w29, w28, \n",
      "        topic 13 (level=2, total_words=1188, documents=42): w5, w6, w9, w8, w7, w16, w17, w1, w0, w18, \n",
      "    topic 193 (level=1, total_words=43, documents=1): w24, w22, w21, w20, w1, w6, w7, w9, w37, w30, \n",
      "        topic 194 (level=2, total_words=0, documents=1): w99, w36, w26, w27, w28, w29, w30, w31, w32, w33, \n",
      "    topic 196 (level=1, total_words=2, documents=1): w8, w73, w99, w35, w26, w27, w28, w29, w30, w31, \n",
      "        topic 197 (level=2, total_words=48, documents=1): w71, w74, w73, w5, w6, w8, w72, w9, w70, w7, \n",
      "..........\n",
      "topic 0 (level=0, total_words=1720, documents=100): w1, w4, w0, w2, w3, w7, w8, w5, w9, w15, \n",
      "    topic 1 (level=1, total_words=4, documents=16): w0, w2, w58, w48, w45, w44, w26, w27, w28, w29, \n",
      "        topic 2 (level=2, total_words=270, documents=9): w10, w14, w11, w5, w13, w6, w9, w8, w12, w7, \n",
      "        topic 3 (level=2, total_words=124, documents=4): w40, w44, w43, w4, w49, w69, w68, w67, w65, w66, \n",
      "        topic 14 (level=2, total_words=76, documents=2): w53, w52, w50, w54, w59, w58, w3, w55, w57, w51, \n",
      "        topic 214 (level=2, total_words=0, documents=1): w99, w36, w26, w27, w28, w29, w30, w31, w32, w33, \n",
      "    topic 6 (level=1, total_words=2, documents=25): w15, w99, w36, w27, w28, w29, w30, w31, w32, w33, \n",
      "        topic 7 (level=2, total_words=721, documents=25): w16, w17, w5, w6, w18, w19, w15, w9, w1, w2, \n",
      "    topic 8 (level=1, total_words=315, documents=58): w24, w20, w22, w1, w6, w9, w2, w8, w21, w4, \n",
      "        topic 9 (level=2, total_words=500, documents=17): w25, w31, w34, w30, w27, w26, w32, w33, w29, w28, \n",
      "        topic 13 (level=2, total_words=1174, documents=40): w5, w6, w9, w8, w7, w16, w17, w0, w18, w19, \n",
      "        topic 215 (level=2, total_words=44, documents=1): w37, w39, w35, w38, w36, w0, w26, w1, w28, w29, \n",
      "    topic 216 (level=1, total_words=0, documents=1): w99, w36, w26, w27, w28, w29, w30, w31, w32, w33, \n",
      "        topic 217 (level=2, total_words=50, documents=1): w71, w74, w73, w8, w5, w6, w72, w9, w70, w7, \n"
     ]
    }
   ],
   "source": [
    "n_samples = 100\n",
    "hlda = HierarchicalLDA(new_corpus, vocab, alpha=1, gamma=1.0, eta=1.0, num_levels=3)\n",
    "hlda.estimate(n_samples, display_topics=10, n_words=10, with_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
